---
title: "Module 2.1 - Correlations"
author: "A. Gamble, I. Ali, N. Zaitlen, R. Wollman"
output: 
 html_document:
 toc: TRUE
 toc_float: TRUE
---

## Setup

In this module, we will use the `ggplot2` package for plotting.

```{r setup, include = FALSE}

knitr::opts_chunk$set(echo = TRUE)

library(ggplot2) # plotting library

```

## Data exploration

### Loading and printing the data

In this module, as in Module 2.1, we will use to use the GeneExpression data we simulated in Module 1.2 Supplement, and visually explored in module 1.3. 

This data set contains information on gene expression (MeanCounts, representing measurements of protein quantities), gene transcription (MeanCountsTranscipt, representing measurements of mRNA quantities), and protein activity (MeanActivity, representing measurements of protein activity). Transcription levels are classically easier to measure (measured by RNA sequencing) than protein expression or activity levels (often measured by immuno-labelling such as immuno-histochemistry or flow-cytometry).

```{r dummydataimport}

# using the read.csv() command import the GeneExpressionData.csv file
dummydata <- read.csv("GeneExpressionData.csv", header = TRUE, sep = ",")

# notice that the data is in long form.
View(dummydata)

```

As in Module 2.1, we aim to assess whether those three variables are correlated or not. We will use a different approach though, based on linear regressions.

Let's start by focusing on the association between gene expression levels and protein activity level.

### Visualizing the data

```{r visualassessment}

# Use ggplot to create a scatter plot comparing transcriptions and expression levels
# length for the species
# Add a linear smooth line
ggplot(data = dummydata, aes(x = MeanCounts, y = MeanActivity)) +
  geom_point() +
  geom_smooth(method = "lm") +
  labs(x = "Transcription level",
       y = "Expression level") 

# Use scale_color_discrete to edit the name and labels for your legend
ggplot(data = dummydata, aes(x = MeanCounts, y = MeanActivity)) +
  geom_point(aes(color = GeneNames)) +
  geom_smooth(method = "lm") +
  labs(x = "Transcription level",
       y = "Expression level") +
  scale_color_discrete(name = "Gene")

```

## Testing correlations with linear regressions

Linear regressions are used to measure the strength and direction of association 
between two variables. Regression is different from correlation because it puts variables into equation and thus explain relationship between them. Linear regressions for instance fit the model `Y = a + b X` to the data. Linear regressions are run under the assumptions of normal distribution and homoscedasticity of the residuals (difference between the observed value and the value predicted by the model).
Linear regressions are obtained with the `lm()` function, which uses the least square method.

When we fit the model `Y = a + b X`, the `lm()` returns an estimate (with a confidence interval) for the intercept (a) and the slope (b), as well as the p-value assessing whether these estimates as significantly different from 0.

```{r lm}

# lm() function to fit the linear model to the data
lm = lm(formula = MeanCounts ~ MeanCountsTranscript, data = dummydata)

# Use summary to obtain the estimates for the parameters a and b, as well as the p-value
summary(lm)

# Plot the residuals to (visually) check that the assumptions are verified
# Here we use the plot() function instead of ggplot() so we do not have to 
# create a data.frame
plot(resid(lm))

```

#### Exercise 1 

We now want to assess whether gene expression level is a good predictor of protein activity level. Repeat the same analysis to assess the association between MeanCounts (expression level) and MeanActivity (activity level). How do you interpret the results?

```{r lm}

# lm() function to fit the linear model to the data
lm = lm(formula = MeanCounts ~ MeanCountsTranscript, data = dummydata)

# Use summary to obtain the estimates for the parameters a and b, as well as the p-value
summary(lm)

# Plot the residuals to (visually) check that the assumptions are verified
# Here we use the plot() function instead of ggplot() so we do not have to 
# create a data.frame
plot(resid(lm))

```

## Multivariate models

Another benefit of linear regressions is that you can easily expand them to multivariate models, including several explanatory variables. 

```{r lm}

# Add a gene effect
lm_time = lm(formula = MeanCounts ~ MeanCountsTranscript + TimePoint, data = dummydata)

# Use summary to obtain the estimates for the parameters a and b, as well as the p-value
summary(lm_time)

# Plot the residuals to (visually) check that the assumptions are verified
plot(resid(lm_time))

# Compared the models with and without a time effect
# with the Akaike Information Criterion
AIC(lm, lm_time)
# The model without a time effect has a lower AIC, suggesting that
# adding the time effect does not improve the fit of the model

```


### Going further

If you want more practice, you can use run similar analyses on the built-in Iris data set. You can for instance explore the correlation between petal length and petal width, with and without a species effect.